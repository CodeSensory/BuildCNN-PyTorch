{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dce5f7-6714-451a-a095-e1a5a0871306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ModelExporter:\n",
    "    \"\"\"\n",
    "    A utility class to export a PyTorch model to an ONNX file.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name):\n",
    "        \"\"\"\n",
    "        Initialize the exporter with a model name.\n",
    "        Args:\n",
    "            model_name (str): The name of the model. This will be used as the ONNX file name.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def export_to_onnx(self, model, dummy_input):\n",
    "        \"\"\"\n",
    "        Exports the given PyTorch model to an ONNX file.\n",
    "        Args:\n",
    "            model (torch.nn.Module): The PyTorch model to be exported.\n",
    "            dummy_input (torch.Tensor): A dummy input tensor that matches the input shape of the model.\n",
    "        \"\"\"\n",
    "        # Generate the ONNX file name using the model name\n",
    "        onnx_file_name = f\"model_onnx/{self.model_name}.onnx\"\n",
    "\n",
    "        # Export the model to ONNX format\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_file_name,           # Name of the output ONNX file\n",
    "            export_params=True,       # Include the trained parameters in the exported file\n",
    "            opset_version=11,         # Specify the ONNX opset version\n",
    "            do_constant_folding=True, # Perform constant folding optimization\n",
    "            input_names=[\"input\"],    # Name of the input tensor\n",
    "            output_names=[\"output\"]   # Name of the output tensor\n",
    "        )\n",
    "        print(f\"The ONNX file has been saved as '{onnx_file_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a141462-e8bc-4727-8a7f-2df88e1dba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomReLU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom implementation of the ReLU activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CustomReLU, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Applies the ReLU function element-wise: max(0, x).\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with ReLU applied\n",
    "        \"\"\"\n",
    "        return torch.maximum(x, torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ef2b6b-0f07-4601-a602-44174a8eb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ConvolutionalLayer:\n",
    "    \"\"\"\n",
    "    A utility class to create a convolutional layer with a custom ReLU activation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def create(in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a convolutional layer with a custom ReLU activation.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_channels (int): Number of output channels\n",
    "            kernel_size (int): Size of the convolution kernel\n",
    "            stride (int): Stride of the convolution\n",
    "            padding (int): Padding added to the input\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential layer containing Conv2d and CustomReLU(+Batch Normalization)\n",
    "        \"\"\"\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            CustomReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2efcacde-ae2d-4e7d-bc5c-f35a806c0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FullyConnectedLayer:\n",
    "    \"\"\"\n",
    "    A utility class to create Fully Connected (FC) layers with Xavier initialization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def Dense(input_dim: int, output_dim: int) -> torch.nn.Linear:\n",
    "        \"\"\"\n",
    "        Creates an FC layer and applies Xavier initialization.\n",
    "        Args:\n",
    "            input_dim (int): Number of input features\n",
    "            output_dim (int): Number of output features\n",
    "        Returns:\n",
    "            torch.nn.Linear: Initialized Fully-Connected layer\n",
    "        \"\"\"\n",
    "        layer = torch.nn.Linear(input_dim, output_dim, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e28546-0cde-424e-b1b0-ee510af9e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomZFNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the introduced by ZFNet model.\n",
    "    Input: Image tensor (batch_size, 3, 224, 224)\n",
    "    Output: Class scores (batch_size, 1000)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CustomZFNet, self).__init__()\n",
    "\n",
    "        # Convolutional and pooling layers\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(3, 96, 7, 2, 1),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(96, 256, 5, 2, 0),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(256, 384, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(384, 384, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(384, 256, 3, 1, 1),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        # Fully Connected layer\n",
    "        self.layer4 = FullyConnectedLayer.Dense(6 * 6 * 256, 4096)\n",
    "\n",
    "        self.layer5 = FullyConnectedLayer.Dense(4096, 4096)\n",
    "\n",
    "        self.layer6 = FullyConnectedLayer.Dense(4096, 1000)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input image tensor (batch_size, 3, 224, 224)\n",
    "        Returns:\n",
    "            torch.Tensor: Class scores (batch_size, 1000)\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde87c1a-4705-4945-ba54-bb40126f0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomZFNet\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 110, 110]          14,208\n",
      "       BatchNorm2d-2         [-1, 96, 110, 110]             192\n",
      "        CustomReLU-3         [-1, 96, 110, 110]               0\n",
      "         MaxPool2d-4           [-1, 96, 55, 55]               0\n",
      "            Conv2d-5          [-1, 256, 26, 26]         614,656\n",
      "       BatchNorm2d-6          [-1, 256, 26, 26]             512\n",
      "        CustomReLU-7          [-1, 256, 26, 26]               0\n",
      "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
      "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
      "      BatchNorm2d-10          [-1, 384, 13, 13]             768\n",
      "       CustomReLU-11          [-1, 384, 13, 13]               0\n",
      "           Conv2d-12          [-1, 384, 13, 13]       1,327,488\n",
      "      BatchNorm2d-13          [-1, 384, 13, 13]             768\n",
      "       CustomReLU-14          [-1, 384, 13, 13]               0\n",
      "           Conv2d-15          [-1, 256, 13, 13]         884,992\n",
      "      BatchNorm2d-16          [-1, 256, 13, 13]             512\n",
      "       CustomReLU-17          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-18            [-1, 256, 6, 6]               0\n",
      "           Linear-19                 [-1, 4096]      37,752,832\n",
      "           Linear-20                 [-1, 4096]      16,781,312\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 62,360,360\n",
      "Trainable params: 62,360,360\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 37.19\n",
      "Params size (MB): 237.89\n",
      "Estimated Total Size (MB): 275.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = CustomZFNet()\n",
    "\n",
    "print(model.__class__.__name__)\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afa7d470-8b23-408b-91f6-b1bc4bfd0afc",
   "metadata": {},
   "source": [
    "# Create a dummy input tensor (adjust its shape to match model)\n",
    "dummy_input = torch.randn(1, 3, 299, 299)  # Shape: (batch_size, channels, height, width)\n",
    "    \n",
    "# Initialize the exporter with the model name and Export the model\n",
    "exporter = ModelExporter(model.__class__.__name__)\n",
    "exporter.export_to_onnx(model, dummy_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
