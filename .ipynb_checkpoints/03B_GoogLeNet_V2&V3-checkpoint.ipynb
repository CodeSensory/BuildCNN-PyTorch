{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e53d0-3940-40a8-9ec8-2c6b62ebe382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomReLU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom implementation of the ReLU activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CustomReLU, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Applies the ReLU function element-wise: max(0, x).\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with ReALU applied\n",
    "        \"\"\"\n",
    "        return torch.maximum(x, torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eea940-b550-4e63-b329-30c7cda5c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ConvolutionalLayer:\n",
    "    \"\"\"\n",
    "    A utility class to create a convolutional layer with a custom ReLU activation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def create(in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a convolutional layer with a custom ReLU activation.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_channels (int): Number of output channels\n",
    "            kernel_size (int): Size of the convolution kernel\n",
    "            stride (int): Stride of the convolution\n",
    "            padding (int): Padding added to the input\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential layer containing Conv2d and CustomReLU(+Batch Normalization)\n",
    "        \"\"\"\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            CustomReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26622b-4486-445e-a538-271aa91d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FullyConnectedLayer:\n",
    "    \"\"\"\n",
    "    A utility class to create Fully Connected (FC) layers with Xavier initialization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def Dense(input_dim: int, output_dim: int) -> torch.nn.Linear:\n",
    "        \"\"\"\n",
    "        Creates an FC layer and applies Xavier initialization.\n",
    "        Args:\n",
    "            input_dim (int): Number of input features\n",
    "            output_dim (int): Number of output features\n",
    "        Returns:\n",
    "            torch.nn.Linear: Initialized Fully-Connected layer\n",
    "        \"\"\"\n",
    "        layer = torch.nn.Linear(input_dim, output_dim, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6a434-18f0-4cf1-9b1d-94e160bebd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Inception_A(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception A layer(Base on Figure 5) introduced by GoogleNet_V2 and V3\n",
    "\n",
    "    Branch 1: 1x1 Convolution\n",
    "    Branch 2: 1×1 → 3×3 Convolution\n",
    "    Branch 3: 1×1 → 3×3 → 3×3 Convolution\n",
    "    Branch 4: Average Pooling → 1×1 Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_branch1: int, reduce_branch2: int, out_branch2: int, \n",
    "                 reduce_branch3: int, out_branch3: int, out_branch4: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a Inception layer with a custom ReLU activation Function.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_branch1 (int): Number of output channels for Branch 1\n",
    "            reduce_branch2 (int): Number of output channels for 3x3 convolution reduction\n",
    "            out_branch2 (int): Number of output channels for Branch 2\n",
    "            reduce_branch3 (int): Number of output channels for 3x3 convolution reduction\n",
    "            out_branch3 (int): Number of output channels for Branch 3\n",
    "            out_branch4 (int): Number of output channels for Branch 4\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential block representing the Inception_A layer\n",
    "        \"\"\"\n",
    "        super(Inception_A, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvolutionalLayer.create(in_channels, out_branch1, 1, 1, 0)\n",
    "        \n",
    "        self.branch2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, reduce_branch2, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(reduce_branch2, out_branch2, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, reduce_branch3, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(reduce_branch3, out_branch3, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(out_branch3, out_branch3, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvolutionalLayer.create(in_channels, out_branch4, 1, 1, 0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the InceptionV1 layer.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through all branches of the Inception_A layer\n",
    "        \"\"\"\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfd0e8-0843-4828-a620-83dd31abf196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Inception_B(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception B layer(Base on Figure 6) introduced by GoogleNet_V2 and V3\n",
    "\n",
    "    Branch 1: 1x1 Convolution\n",
    "    Branch 2: 1×1 → 1×7 → 7×1 Convolution\n",
    "    Branch 3: 1×1 → 7×1 → 1×7 → 7×1 → 1×7 Convolution\n",
    "    Branch 4: Max Pooling → 1×1 Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a Inception layer with a custom ReLU activation Function.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_channels (int): Number of output channels\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential block representing the Inception_B layer\n",
    "        \"\"\"\n",
    "        super(Inception_B, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvolutionalLayer.create(in_channels, 192, 1, 1, 0)  # Output value is fixed to 192\n",
    "        \n",
    "        self.branch2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, 192, 1, 1, 0),\n",
    "            ConvolutionalLayer.create(192, 384, (1, 7), 1, (0, 3)),\n",
    "            ConvolutionalLayer.create(384, 384, (7, 1), 1, (3, 0))\n",
    "        )\n",
    "\n",
    "        self.branch3 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, 192, 1, 1, 0),\n",
    "            ConvolutionalLayer.create(192, 384, (1, 7), 1, (0, 3)),\n",
    "            ConvolutionalLayer.create(384, 384, (7, 1), 1, (3, 0)),\n",
    "            ConvolutionalLayer.create(384, 384, (1, 7), 1, (0, 3)),\n",
    "            ConvolutionalLayer.create(384, 384, (7, 1), 1, (3, 0))\n",
    "        )\n",
    "\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvolutionalLayer.create(in_channels, 320, 1, 1, 0)    # Output value is fixed to 320\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the InceptionV1 layer.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through all branches of the Inception_A layer\n",
    "        \"\"\"\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82847a08-bf8e-4b69-8ddb-368c35aa1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Inception_C(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception C layer(Base on Figure 7) introduced by GoogleNet_V2 and V3\n",
    "\n",
    "    Branch 1: 1x1 Convolution\n",
    "    Branch 2: 1×1 → (1×3 + 3×1) Convolution\n",
    "    Branch 3: 1×1 → 3×3 → (1×3 + 3×1) Convolution\n",
    "    Branch 4: Average Pooling → 1×1 Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_branch1: int, reduce_branch2: int, \n",
    "                 reduce_branch3: int, out_branch4: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a Inception layer with a custom ReLU activation Function.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_branch1 (int): Number of output channels for Branch 1\n",
    "            reduce_branch2 (int): Number of output channels for 3x3 convolution reduction\n",
    "            reduce_branch3 (int): Number of output channels for 3x3 convolution reduction\n",
    "            out_branch4 (int): Number of output channels for Branch 4\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential block representing the Inception_A layer\n",
    "        \"\"\"\n",
    "        super(Inception_C, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvolutionalLayer.create(in_channels, out_branch1, 1, 1, 0)\n",
    "        \n",
    "        self.branch2_a = ConvolutionalLayer.create(in_channels, 384, 1, 1, 0)\n",
    "        self.branch2_b1 = ConvolutionalLayer.create(384, reduce_branch2, (1, 3), 1, (0, 1))\n",
    "        self.branch2_b2 = ConvolutionalLayer.create(384, reduce_branch2, (3, 1), 1, (1, 0))\n",
    "\n",
    "        self.branch3_a = ConvolutionalLayer.create(in_channels, 384, 1, 1, 0)\n",
    "        self.branch3_b = ConvolutionalLayer.create(384, 448, 1, 1, 0)\n",
    "        self.branch3_c1 = ConvolutionalLayer.create(448, reduce_branch3, (1, 3), 1, (0, 1))\n",
    "        self.branch3_c2 = ConvolutionalLayer.create(448, reduce_branch3, (3, 1), 1, (1, 0))\n",
    "\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvolutionalLayer.create(in_channels, out_branch4, 1, 1, 0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the InceptionV1 layer.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through all branches of the Inception_A layer\n",
    "        \"\"\"\n",
    "        x_b1 = self.branch1(x)\n",
    "\n",
    "        x_b2_a = self.branch2_a(x)\n",
    "        x_b2_b1 = self.branch2_b1(x_b2_a)\n",
    "        x_b2_b2 = self.branch2_b2(x_b2_a)\n",
    "        x_b2_cat = torch.cat([x_b2_b1, x_b2_b2], dim=1)\n",
    "\n",
    "        x_b3_a = self.branch3_a(x)\n",
    "        x_b3_b = self.branch3_b(x_b3_a)\n",
    "        x_b3_c1 = self.branch3_c1(x_b3_b)\n",
    "        x_b3_c2 = self.branch3_c2(x_b3_b)\n",
    "        x_b3_cat = torch.cat([x_b3_c1, x_b3_c2], dim=1)\n",
    "\n",
    "        x_b4 = self.branch4(x)\n",
    "\n",
    "        return torch.cat([x_b1, x_b2_cat, x_b3_cat, x_b4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7abf1-d37b-4abf-8b56-e81be5c4ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomGoogLeNet_V3(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GoogLeNet_V2 and V3 model.\n",
    "    Input: Image tensor (batch_size, 3, 299, 299)\n",
    "    Output: Class scores (batch_size, 1000)\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_rate=0.4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dropout_rate (float): Dropout Rate = 0.4(Base on Paper)\n",
    "        \"\"\"\n",
    "        super(CustomGoogLeNet_V3, self).__init__()\n",
    "\n",
    "        # Convolutional and pooling layers\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(3, 32, 3, 2, 0),\n",
    "            ConvolutionalLayer.create(32, 32, 3, 1, 0),\n",
    "            ConvolutionalLayer.create(32, 64, 3, 1, 1),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(64, 80, 3, 1, 0),\n",
    "            ConvolutionalLayer.create(80, 192, 3, 2, 0),\n",
    "            ConvolutionalLayer.create(192, 288, 3, 1, 1),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            Inception_A(288, 64, 48, 64, 64, 96, 32),\n",
    "            Inception_A(256, 64, 48, 64, 64, 96, 64),\n",
    "            Inception_A(288, 128, 128, 256, 128, 256, 128),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            Inception_B(768, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            Inception_C(1280, 256, 192, 192, 128),\n",
    "            Inception_C(1152, 384, 352, 352, 256),\n",
    "            torch.nn.AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        # Fully Connected layers and dropout\n",
    "        self.layer_drop = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.layer6 = FullyConnectedLayer.Dense(1 * 1 * 2048, 1000)\n",
    "\n",
    "        self.layer7 = FullyConnectedLayer.Dense(1000, 1000)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input image tensor (batch_size, 3, 224, 224)\n",
    "        Returns:\n",
    "            torch.Tensor: Class scores (batch_size, 1000)\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer_drop(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706fc53-973b-4e8f-a943-a097da5099f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = CustomGoogLeNet_V3()\n",
    "summary(model, input_size=(3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650956b-ac0c-4bbe-a053-0d585765090c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
