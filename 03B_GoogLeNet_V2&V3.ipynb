{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5e53d0-3940-40a8-9ec8-2c6b62ebe382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomReLU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom implementation of the ReLU activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CustomReLU, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Applies the ReLU function element-wise: max(0, x).\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with ReALU applied\n",
    "        \"\"\"\n",
    "        return torch.maximum(x, torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eea940-b550-4e63-b329-30c7cda5c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ConvolutionalLayer:\n",
    "    \"\"\"\n",
    "    A utility class to create a convolutional layer with a custom ReLU activation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def create(in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a convolutional layer with a custom ReLU activation.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_channels (int): Number of output channels\n",
    "            kernel_size (int): Size of the convolution kernel\n",
    "            stride (int): Stride of the convolution\n",
    "            padding (int): Padding added to the input\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential layer containing Conv2d and CustomReLU(+Batch Normalization)\n",
    "        \"\"\"\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            CustomReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a26622b-4486-445e-a538-271aa91d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FullyConnectedLayer:\n",
    "    \"\"\"\n",
    "    A utility class to create Fully Connected (FC) layers with Xavier initialization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def Dense(input_dim: int, output_dim: int) -> torch.nn.Linear:\n",
    "        \"\"\"\n",
    "        Creates an FC layer and applies Xavier initialization.\n",
    "        Args:\n",
    "            input_dim (int): Number of input features\n",
    "            output_dim (int): Number of output features\n",
    "        Returns:\n",
    "            torch.nn.Linear: Initialized Fully-Connected layer\n",
    "        \"\"\"\n",
    "        layer = torch.nn.Linear(input_dim, output_dim, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f6a434-18f0-4cf1-9b1d-94e160bebd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Inception_A(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception A layer(Base on Figure 5) introduced by GoogleNet_V2 and V3\n",
    "\n",
    "    Branch 1: 1x1 Convolution\n",
    "    Branch 2: 1×1 → 3×3 Convolution\n",
    "    Branch 3: 1×1 → 3×3 → 3×3 Convolution\n",
    "    Branch 4: Average Pooling → 1×1 Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_branch1: int, reduce_branch2: int, out_branch2: int, \n",
    "                 reduce_branch3: int, out_branch3: int, out_branch4: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a Inception layer with a custom ReLU activation Function.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_branch1 (int): Number of output channels for Branch 1\n",
    "            reduce_branch2 (int): Number of output channels for 3x3 convolution reduction\n",
    "            out_branch2 (int): Number of output channels for Branch 2\n",
    "            reduce_branch3 (int): Number of output channels for 3x3 convolution reduction\n",
    "            out_branch3 (int): Number of output channels for Branch 3\n",
    "            out_branch4 (int): Number of output channels for Branch 4\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential block representing the Inception_A layer\n",
    "        \"\"\"\n",
    "        super(Inception_A, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvolutionalLayer.create(in_channels, out_branch1, 1, 1, 0)\n",
    "        \n",
    "        self.branch2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, reduce_branch2, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(reduce_branch2, out_branch2, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, reduce_branch3, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(reduce_branch3, out_branch3, 3, 1, 1),\n",
    "            ConvolutionalLayer.create(out_branch3, out_branch3, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvolutionalLayer.create(in_channels, out_branch4, 1, 1, 0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the InceptionV1 layer.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through all branches of the Inception_A layer\n",
    "        \"\"\"\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcfd0e8-0843-4828-a620-83dd31abf196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Inception_B(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception B layer(Base on Figure 6) introduced by GoogleNet_V2 and V3\n",
    "\n",
    "    Branch 1: 1x1 Convolution\n",
    "    Branch 2: 1×1 → 1×7 → 7×1 Convolution\n",
    "    Branch 3: 1×1 → 7×1 → 1×7 → 7×1 → 1×7 Convolution\n",
    "    Branch 4: Max Pooling → 1×1 Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a Inception layer with a custom ReLU activation Function.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_channels (int): Number of output channels\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential block representing the Inception_B layer\n",
    "        \"\"\"\n",
    "        super(Inception_B, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvolutionalLayer.create(in_channels, 192, 1, 1, 0)  # Output value is fixed to 192\n",
    "        \n",
    "        self.branch2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, 192, 1, 1, 0),\n",
    "            ConvolutionalLayer.create(192, 384, (1, 7), 1, (0, 3)),\n",
    "            ConvolutionalLayer.create(384, 384, (7, 1), 1, (3, 0))\n",
    "        )\n",
    "\n",
    "        self.branch3 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(in_channels, 192, 1, 1, 0),\n",
    "            ConvolutionalLayer.create(192, 384, (1, 7), 1, (0, 3)),\n",
    "            ConvolutionalLayer.create(384, 384, (7, 1), 1, (3, 0)),\n",
    "            ConvolutionalLayer.create(384, 384, (1, 7), 1, (0, 3)),\n",
    "            ConvolutionalLayer.create(384, 384, (7, 1), 1, (3, 0))\n",
    "        )\n",
    "\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvolutionalLayer.create(in_channels, 320, 1, 1, 0)    # Output value is fixed to 320\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the InceptionV1 layer.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through all branches of the Inception_A layer\n",
    "        \"\"\"\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82847a08-bf8e-4b69-8ddb-368c35aa1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Inception_C(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception C layer(Base on Figure 7) introduced by GoogleNet_V2 and V3\n",
    "\n",
    "    Branch 1: 1x1 Convolution\n",
    "    Branch 2: 1×1 → (1×3 + 3×1) Convolution\n",
    "    Branch 3: 1×1 → 3×3 → (1×3 + 3×1) Convolution\n",
    "    Branch 4: Average Pooling → 1×1 Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_branch1: int, reduce_branch2: int, \n",
    "                 reduce_branch3: int, out_branch4: int) -> torch.nn.Sequential:\n",
    "        \"\"\"\n",
    "        Creates a Inception layer with a custom ReLU activation Function.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "            out_branch1 (int): Number of output channels for Branch 1\n",
    "            reduce_branch2 (int): Number of output channels for 3x3 convolution reduction\n",
    "            reduce_branch3 (int): Number of output channels for 3x3 convolution reduction\n",
    "            out_branch4 (int): Number of output channels for Branch 4\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential block representing the Inception_A layer\n",
    "        \"\"\"\n",
    "        super(Inception_C, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvolutionalLayer.create(in_channels, out_branch1, 1, 1, 0)\n",
    "        \n",
    "        self.branch2_a = ConvolutionalLayer.create(in_channels, 384, 1, 1, 0)\n",
    "        self.branch2_b1 = ConvolutionalLayer.create(384, reduce_branch2, (1, 3), 1, (0, 1))\n",
    "        self.branch2_b2 = ConvolutionalLayer.create(384, reduce_branch2, (3, 1), 1, (1, 0))\n",
    "\n",
    "        self.branch3_a = ConvolutionalLayer.create(in_channels, 384, 1, 1, 0)\n",
    "        self.branch3_b = ConvolutionalLayer.create(384, 448, 1, 1, 0)\n",
    "        self.branch3_c1 = ConvolutionalLayer.create(448, reduce_branch3, (1, 3), 1, (0, 1))\n",
    "        self.branch3_c2 = ConvolutionalLayer.create(448, reduce_branch3, (3, 1), 1, (1, 0))\n",
    "\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvolutionalLayer.create(in_channels, out_branch4, 1, 1, 0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the InceptionV1 layer.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through all branches of the Inception_A layer\n",
    "        \"\"\"\n",
    "        x_b1 = self.branch1(x)\n",
    "\n",
    "        x_b2_a = self.branch2_a(x)\n",
    "        x_b2_b1 = self.branch2_b1(x_b2_a)\n",
    "        x_b2_b2 = self.branch2_b2(x_b2_a)\n",
    "        x_b2_cat = torch.cat([x_b2_b1, x_b2_b2], dim=1)\n",
    "\n",
    "        x_b3_a = self.branch3_a(x)\n",
    "        x_b3_b = self.branch3_b(x_b3_a)\n",
    "        x_b3_c1 = self.branch3_c1(x_b3_b)\n",
    "        x_b3_c2 = self.branch3_c2(x_b3_b)\n",
    "        x_b3_cat = torch.cat([x_b3_c1, x_b3_c2], dim=1)\n",
    "\n",
    "        x_b4 = self.branch4(x)\n",
    "\n",
    "        return torch.cat([x_b1, x_b2_cat, x_b3_cat, x_b4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d7abf1-d37b-4abf-8b56-e81be5c4ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomGoogLeNet_V3(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GoogLeNet_V2 and V3 model.\n",
    "    Input: Image tensor (batch_size, 3, 299, 299)\n",
    "    Output: Class scores (batch_size, 1000)\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_rate=0.4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dropout_rate (float): Dropout Rate = 0.4(Base on Paper)\n",
    "        \"\"\"\n",
    "        super(CustomGoogLeNet_V3, self).__init__()\n",
    "\n",
    "        # Convolutional and pooling layers\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(3, 32, 3, 2, 0),\n",
    "            ConvolutionalLayer.create(32, 32, 3, 1, 0),\n",
    "            ConvolutionalLayer.create(32, 64, 3, 1, 1),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            ConvolutionalLayer.create(64, 80, 3, 1, 0),\n",
    "            ConvolutionalLayer.create(80, 192, 3, 2, 0),\n",
    "            ConvolutionalLayer.create(192, 288, 3, 1, 1),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            Inception_A(288, 64, 48, 64, 64, 96, 32),\n",
    "            Inception_A(256, 64, 48, 64, 64, 96, 64),\n",
    "            Inception_A(288, 128, 128, 256, 128, 256, 128),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            Inception_B(768, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            Inception_B(1280, 1280),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            Inception_C(1280, 256, 192, 192, 128),\n",
    "            Inception_C(1152, 384, 352, 352, 256),\n",
    "            torch.nn.AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        # Fully Connected layers and dropout\n",
    "        self.layer_drop = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.layer6 = FullyConnectedLayer.Dense(1 * 1 * 2048, 1000)\n",
    "\n",
    "        self.layer7 = FullyConnectedLayer.Dense(1000, 1000)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input image tensor (batch_size, 3, 224, 224)\n",
    "        Returns:\n",
    "            torch.Tensor: Class scores (batch_size, 1000)\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer_drop(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b706fc53-973b-4e8f-a943-a097da5099f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 149, 149]             896\n",
      "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
      "        CustomReLU-3         [-1, 32, 149, 149]               0\n",
      "            Conv2d-4         [-1, 32, 147, 147]           9,248\n",
      "       BatchNorm2d-5         [-1, 32, 147, 147]              64\n",
      "        CustomReLU-6         [-1, 32, 147, 147]               0\n",
      "            Conv2d-7         [-1, 64, 147, 147]          18,496\n",
      "       BatchNorm2d-8         [-1, 64, 147, 147]             128\n",
      "        CustomReLU-9         [-1, 64, 147, 147]               0\n",
      "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
      "           Conv2d-11           [-1, 80, 71, 71]          46,160\n",
      "      BatchNorm2d-12           [-1, 80, 71, 71]             160\n",
      "       CustomReLU-13           [-1, 80, 71, 71]               0\n",
      "           Conv2d-14          [-1, 192, 35, 35]         138,432\n",
      "      BatchNorm2d-15          [-1, 192, 35, 35]             384\n",
      "       CustomReLU-16          [-1, 192, 35, 35]               0\n",
      "           Conv2d-17          [-1, 288, 35, 35]         497,952\n",
      "      BatchNorm2d-18          [-1, 288, 35, 35]             576\n",
      "       CustomReLU-19          [-1, 288, 35, 35]               0\n",
      "        MaxPool2d-20          [-1, 288, 35, 35]               0\n",
      "           Conv2d-21           [-1, 64, 35, 35]          18,496\n",
      "      BatchNorm2d-22           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-23           [-1, 64, 35, 35]               0\n",
      "           Conv2d-24           [-1, 48, 35, 35]         124,464\n",
      "      BatchNorm2d-25           [-1, 48, 35, 35]              96\n",
      "       CustomReLU-26           [-1, 48, 35, 35]               0\n",
      "           Conv2d-27           [-1, 64, 35, 35]          27,712\n",
      "      BatchNorm2d-28           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-29           [-1, 64, 35, 35]               0\n",
      "           Conv2d-30           [-1, 64, 35, 35]         165,952\n",
      "      BatchNorm2d-31           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-32           [-1, 64, 35, 35]               0\n",
      "           Conv2d-33           [-1, 96, 35, 35]          55,392\n",
      "      BatchNorm2d-34           [-1, 96, 35, 35]             192\n",
      "       CustomReLU-35           [-1, 96, 35, 35]               0\n",
      "           Conv2d-36           [-1, 96, 35, 35]          83,040\n",
      "      BatchNorm2d-37           [-1, 96, 35, 35]             192\n",
      "       CustomReLU-38           [-1, 96, 35, 35]               0\n",
      "        AvgPool2d-39          [-1, 288, 35, 35]               0\n",
      "           Conv2d-40           [-1, 32, 35, 35]           9,248\n",
      "      BatchNorm2d-41           [-1, 32, 35, 35]              64\n",
      "       CustomReLU-42           [-1, 32, 35, 35]               0\n",
      "      Inception_A-43          [-1, 256, 35, 35]               0\n",
      "           Conv2d-44           [-1, 64, 35, 35]          16,448\n",
      "      BatchNorm2d-45           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-46           [-1, 64, 35, 35]               0\n",
      "           Conv2d-47           [-1, 48, 35, 35]         110,640\n",
      "      BatchNorm2d-48           [-1, 48, 35, 35]              96\n",
      "       CustomReLU-49           [-1, 48, 35, 35]               0\n",
      "           Conv2d-50           [-1, 64, 35, 35]          27,712\n",
      "      BatchNorm2d-51           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-52           [-1, 64, 35, 35]               0\n",
      "           Conv2d-53           [-1, 64, 35, 35]         147,520\n",
      "      BatchNorm2d-54           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-55           [-1, 64, 35, 35]               0\n",
      "           Conv2d-56           [-1, 96, 35, 35]          55,392\n",
      "      BatchNorm2d-57           [-1, 96, 35, 35]             192\n",
      "       CustomReLU-58           [-1, 96, 35, 35]               0\n",
      "           Conv2d-59           [-1, 96, 35, 35]          83,040\n",
      "      BatchNorm2d-60           [-1, 96, 35, 35]             192\n",
      "       CustomReLU-61           [-1, 96, 35, 35]               0\n",
      "        AvgPool2d-62          [-1, 256, 35, 35]               0\n",
      "           Conv2d-63           [-1, 64, 35, 35]          16,448\n",
      "      BatchNorm2d-64           [-1, 64, 35, 35]             128\n",
      "       CustomReLU-65           [-1, 64, 35, 35]               0\n",
      "      Inception_A-66          [-1, 288, 35, 35]               0\n",
      "           Conv2d-67          [-1, 128, 35, 35]          36,992\n",
      "      BatchNorm2d-68          [-1, 128, 35, 35]             256\n",
      "       CustomReLU-69          [-1, 128, 35, 35]               0\n",
      "           Conv2d-70          [-1, 128, 35, 35]         331,904\n",
      "      BatchNorm2d-71          [-1, 128, 35, 35]             256\n",
      "       CustomReLU-72          [-1, 128, 35, 35]               0\n",
      "           Conv2d-73          [-1, 256, 35, 35]         295,168\n",
      "      BatchNorm2d-74          [-1, 256, 35, 35]             512\n",
      "       CustomReLU-75          [-1, 256, 35, 35]               0\n",
      "           Conv2d-76          [-1, 128, 35, 35]         331,904\n",
      "      BatchNorm2d-77          [-1, 128, 35, 35]             256\n",
      "       CustomReLU-78          [-1, 128, 35, 35]               0\n",
      "           Conv2d-79          [-1, 256, 35, 35]         295,168\n",
      "      BatchNorm2d-80          [-1, 256, 35, 35]             512\n",
      "       CustomReLU-81          [-1, 256, 35, 35]               0\n",
      "           Conv2d-82          [-1, 256, 35, 35]         590,080\n",
      "      BatchNorm2d-83          [-1, 256, 35, 35]             512\n",
      "       CustomReLU-84          [-1, 256, 35, 35]               0\n",
      "        AvgPool2d-85          [-1, 288, 35, 35]               0\n",
      "           Conv2d-86          [-1, 128, 35, 35]          36,992\n",
      "      BatchNorm2d-87          [-1, 128, 35, 35]             256\n",
      "       CustomReLU-88          [-1, 128, 35, 35]               0\n",
      "      Inception_A-89          [-1, 768, 35, 35]               0\n",
      "        MaxPool2d-90          [-1, 768, 17, 17]               0\n",
      "           Conv2d-91          [-1, 192, 17, 17]         147,648\n",
      "      BatchNorm2d-92          [-1, 192, 17, 17]             384\n",
      "       CustomReLU-93          [-1, 192, 17, 17]               0\n",
      "           Conv2d-94          [-1, 192, 17, 17]         147,648\n",
      "      BatchNorm2d-95          [-1, 192, 17, 17]             384\n",
      "       CustomReLU-96          [-1, 192, 17, 17]               0\n",
      "           Conv2d-97          [-1, 384, 17, 17]         516,480\n",
      "      BatchNorm2d-98          [-1, 384, 17, 17]             768\n",
      "       CustomReLU-99          [-1, 384, 17, 17]               0\n",
      "          Conv2d-100          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-101          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-102          [-1, 384, 17, 17]               0\n",
      "          Conv2d-103          [-1, 192, 17, 17]         147,648\n",
      "     BatchNorm2d-104          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-105          [-1, 192, 17, 17]               0\n",
      "          Conv2d-106          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-107          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-108          [-1, 384, 17, 17]               0\n",
      "          Conv2d-109          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-110          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-111          [-1, 384, 17, 17]               0\n",
      "          Conv2d-112          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-113          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-114          [-1, 384, 17, 17]               0\n",
      "          Conv2d-115          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-116          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-117          [-1, 384, 17, 17]               0\n",
      "       MaxPool2d-118          [-1, 768, 17, 17]               0\n",
      "          Conv2d-119          [-1, 320, 17, 17]         246,080\n",
      "     BatchNorm2d-120          [-1, 320, 17, 17]             640\n",
      "      CustomReLU-121          [-1, 320, 17, 17]               0\n",
      "     Inception_B-122         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-123          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-124          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-125          [-1, 192, 17, 17]               0\n",
      "          Conv2d-126          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-127          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-128          [-1, 192, 17, 17]               0\n",
      "          Conv2d-129          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-130          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-131          [-1, 384, 17, 17]               0\n",
      "          Conv2d-132          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-133          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-134          [-1, 384, 17, 17]               0\n",
      "          Conv2d-135          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-136          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-137          [-1, 192, 17, 17]               0\n",
      "          Conv2d-138          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-139          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-140          [-1, 384, 17, 17]               0\n",
      "          Conv2d-141          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-142          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-143          [-1, 384, 17, 17]               0\n",
      "          Conv2d-144          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-145          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-146          [-1, 384, 17, 17]               0\n",
      "          Conv2d-147          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-148          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-149          [-1, 384, 17, 17]               0\n",
      "       MaxPool2d-150         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-151          [-1, 320, 17, 17]         409,920\n",
      "     BatchNorm2d-152          [-1, 320, 17, 17]             640\n",
      "      CustomReLU-153          [-1, 320, 17, 17]               0\n",
      "     Inception_B-154         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-155          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-156          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-157          [-1, 192, 17, 17]               0\n",
      "          Conv2d-158          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-159          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-160          [-1, 192, 17, 17]               0\n",
      "          Conv2d-161          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-162          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-163          [-1, 384, 17, 17]               0\n",
      "          Conv2d-164          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-165          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-166          [-1, 384, 17, 17]               0\n",
      "          Conv2d-167          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-168          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-169          [-1, 192, 17, 17]               0\n",
      "          Conv2d-170          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-171          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-172          [-1, 384, 17, 17]               0\n",
      "          Conv2d-173          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-174          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-175          [-1, 384, 17, 17]               0\n",
      "          Conv2d-176          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-177          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-178          [-1, 384, 17, 17]               0\n",
      "          Conv2d-179          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-180          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-181          [-1, 384, 17, 17]               0\n",
      "       MaxPool2d-182         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-183          [-1, 320, 17, 17]         409,920\n",
      "     BatchNorm2d-184          [-1, 320, 17, 17]             640\n",
      "      CustomReLU-185          [-1, 320, 17, 17]               0\n",
      "     Inception_B-186         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-187          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-188          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-189          [-1, 192, 17, 17]               0\n",
      "          Conv2d-190          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-191          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-192          [-1, 192, 17, 17]               0\n",
      "          Conv2d-193          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-194          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-195          [-1, 384, 17, 17]               0\n",
      "          Conv2d-196          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-197          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-198          [-1, 384, 17, 17]               0\n",
      "          Conv2d-199          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-200          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-201          [-1, 192, 17, 17]               0\n",
      "          Conv2d-202          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-203          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-204          [-1, 384, 17, 17]               0\n",
      "          Conv2d-205          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-206          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-207          [-1, 384, 17, 17]               0\n",
      "          Conv2d-208          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-209          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-210          [-1, 384, 17, 17]               0\n",
      "          Conv2d-211          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-212          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-213          [-1, 384, 17, 17]               0\n",
      "       MaxPool2d-214         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-215          [-1, 320, 17, 17]         409,920\n",
      "     BatchNorm2d-216          [-1, 320, 17, 17]             640\n",
      "      CustomReLU-217          [-1, 320, 17, 17]               0\n",
      "     Inception_B-218         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-219          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-220          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-221          [-1, 192, 17, 17]               0\n",
      "          Conv2d-222          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-223          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-224          [-1, 192, 17, 17]               0\n",
      "          Conv2d-225          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-226          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-227          [-1, 384, 17, 17]               0\n",
      "          Conv2d-228          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-229          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-230          [-1, 384, 17, 17]               0\n",
      "          Conv2d-231          [-1, 192, 17, 17]         245,952\n",
      "     BatchNorm2d-232          [-1, 192, 17, 17]             384\n",
      "      CustomReLU-233          [-1, 192, 17, 17]               0\n",
      "          Conv2d-234          [-1, 384, 17, 17]         516,480\n",
      "     BatchNorm2d-235          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-236          [-1, 384, 17, 17]               0\n",
      "          Conv2d-237          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-238          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-239          [-1, 384, 17, 17]               0\n",
      "          Conv2d-240          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-241          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-242          [-1, 384, 17, 17]               0\n",
      "          Conv2d-243          [-1, 384, 17, 17]       1,032,576\n",
      "     BatchNorm2d-244          [-1, 384, 17, 17]             768\n",
      "      CustomReLU-245          [-1, 384, 17, 17]               0\n",
      "       MaxPool2d-246         [-1, 1280, 17, 17]               0\n",
      "          Conv2d-247          [-1, 320, 17, 17]         409,920\n",
      "     BatchNorm2d-248          [-1, 320, 17, 17]             640\n",
      "      CustomReLU-249          [-1, 320, 17, 17]               0\n",
      "     Inception_B-250         [-1, 1280, 17, 17]               0\n",
      "       MaxPool2d-251           [-1, 1280, 8, 8]               0\n",
      "          Conv2d-252            [-1, 256, 8, 8]         327,936\n",
      "     BatchNorm2d-253            [-1, 256, 8, 8]             512\n",
      "      CustomReLU-254            [-1, 256, 8, 8]               0\n",
      "          Conv2d-255            [-1, 384, 8, 8]         491,904\n",
      "     BatchNorm2d-256            [-1, 384, 8, 8]             768\n",
      "      CustomReLU-257            [-1, 384, 8, 8]               0\n",
      "          Conv2d-258            [-1, 192, 8, 8]         221,376\n",
      "     BatchNorm2d-259            [-1, 192, 8, 8]             384\n",
      "      CustomReLU-260            [-1, 192, 8, 8]               0\n",
      "          Conv2d-261            [-1, 192, 8, 8]         221,376\n",
      "     BatchNorm2d-262            [-1, 192, 8, 8]             384\n",
      "      CustomReLU-263            [-1, 192, 8, 8]               0\n",
      "          Conv2d-264            [-1, 384, 8, 8]         491,904\n",
      "     BatchNorm2d-265            [-1, 384, 8, 8]             768\n",
      "      CustomReLU-266            [-1, 384, 8, 8]               0\n",
      "          Conv2d-267            [-1, 448, 8, 8]         172,480\n",
      "     BatchNorm2d-268            [-1, 448, 8, 8]             896\n",
      "      CustomReLU-269            [-1, 448, 8, 8]               0\n",
      "          Conv2d-270            [-1, 192, 8, 8]         258,240\n",
      "     BatchNorm2d-271            [-1, 192, 8, 8]             384\n",
      "      CustomReLU-272            [-1, 192, 8, 8]               0\n",
      "          Conv2d-273            [-1, 192, 8, 8]         258,240\n",
      "     BatchNorm2d-274            [-1, 192, 8, 8]             384\n",
      "      CustomReLU-275            [-1, 192, 8, 8]               0\n",
      "       AvgPool2d-276           [-1, 1280, 8, 8]               0\n",
      "          Conv2d-277            [-1, 128, 8, 8]         163,968\n",
      "     BatchNorm2d-278            [-1, 128, 8, 8]             256\n",
      "      CustomReLU-279            [-1, 128, 8, 8]               0\n",
      "     Inception_C-280           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-281            [-1, 384, 8, 8]         442,752\n",
      "     BatchNorm2d-282            [-1, 384, 8, 8]             768\n",
      "      CustomReLU-283            [-1, 384, 8, 8]               0\n",
      "          Conv2d-284            [-1, 384, 8, 8]         442,752\n",
      "     BatchNorm2d-285            [-1, 384, 8, 8]             768\n",
      "      CustomReLU-286            [-1, 384, 8, 8]               0\n",
      "          Conv2d-287            [-1, 352, 8, 8]         405,856\n",
      "     BatchNorm2d-288            [-1, 352, 8, 8]             704\n",
      "      CustomReLU-289            [-1, 352, 8, 8]               0\n",
      "          Conv2d-290            [-1, 352, 8, 8]         405,856\n",
      "     BatchNorm2d-291            [-1, 352, 8, 8]             704\n",
      "      CustomReLU-292            [-1, 352, 8, 8]               0\n",
      "          Conv2d-293            [-1, 384, 8, 8]         442,752\n",
      "     BatchNorm2d-294            [-1, 384, 8, 8]             768\n",
      "      CustomReLU-295            [-1, 384, 8, 8]               0\n",
      "          Conv2d-296            [-1, 448, 8, 8]         172,480\n",
      "     BatchNorm2d-297            [-1, 448, 8, 8]             896\n",
      "      CustomReLU-298            [-1, 448, 8, 8]               0\n",
      "          Conv2d-299            [-1, 352, 8, 8]         473,440\n",
      "     BatchNorm2d-300            [-1, 352, 8, 8]             704\n",
      "      CustomReLU-301            [-1, 352, 8, 8]               0\n",
      "          Conv2d-302            [-1, 352, 8, 8]         473,440\n",
      "     BatchNorm2d-303            [-1, 352, 8, 8]             704\n",
      "      CustomReLU-304            [-1, 352, 8, 8]               0\n",
      "       AvgPool2d-305           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-306            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-307            [-1, 256, 8, 8]             512\n",
      "      CustomReLU-308            [-1, 256, 8, 8]               0\n",
      "     Inception_C-309           [-1, 2048, 8, 8]               0\n",
      "       AvgPool2d-310           [-1, 2048, 1, 1]               0\n",
      "         Dropout-311           [-1, 2048, 1, 1]               0\n",
      "          Linear-312                 [-1, 1000]       2,049,000\n",
      "          Linear-313                 [-1, 1000]       1,001,000\n",
      "================================================================\n",
      "Total params: 43,928,384\n",
      "Trainable params: 43,928,384\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 320.86\n",
      "Params size (MB): 167.57\n",
      "Estimated Total Size (MB): 489.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = CustomGoogLeNet_V3()\n",
    "summary(model, input_size=(3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650956b-ac0c-4bbe-a053-0d585765090c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
